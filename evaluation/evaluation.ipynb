{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import sys\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "sys.path.append(\"../scripts\")\n",
    "sys.path.append(\"../utility\")\n",
    "\n",
    "from network import KoopmanNet\n",
    "\n",
    "project_name = \"Koopman_Results_Apr_8_2\"\n",
    "#project_name = \"Test\"\n",
    "gamma = 0.8\n",
    "\n",
    "if not os.path.exists(project_name):\n",
    "    os.makedirs(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, u_dim, gamma, state_dim, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        steps = data.shape[0]\n",
    "        if u_dim is None:\n",
    "            X = model.encode(data[0].to(device))\n",
    "        else:\n",
    "            X = model.encode(data[0, :, u_dim:].to(device))\n",
    "\n",
    "        encoded_initial = X[:, state_dim:]\n",
    "        \n",
    "        weighted_loss = 0.0\n",
    "        beta = 1.0\n",
    "        beta_sum = 0.0\n",
    "        step_errors = []\n",
    "\n",
    "        for i in range(steps - 1):\n",
    "            if u_dim is None:\n",
    "                X = model.forward(X, None)\n",
    "                target = data[i+1].to(device)\n",
    "            else:\n",
    "                X = model.forward(X, data[i, :, :u_dim].to(device))\n",
    "                target = data[i+1, :, u_dim:].to(device)\n",
    "            error = nn.MSELoss()(X[:, :state_dim], target)\n",
    "            step_errors.append(error.item())\n",
    "            weighted_loss += beta * error\n",
    "            beta_sum += beta\n",
    "            beta *= gamma\n",
    "        weighted_loss /= beta_sum\n",
    "\n",
    "        z = encoded_initial\n",
    "        z_mean = torch.mean(z, dim=0, keepdim=True)\n",
    "        z_centered = z - z_mean\n",
    "        cov_matrix = (z_centered.t() @ z_centered) / (z_centered.size(0) - 1)\n",
    "        diag_cov = torch.diag(torch.diag(cov_matrix))\n",
    "        off_diag = cov_matrix - diag_cov\n",
    "        cov_loss_val = torch.norm(off_diag, p='fro')**2\n",
    "        encode_dim = X.shape[1] - state_dim\n",
    "        normalized_cov_loss = (cov_loss_val.item() / (encode_dim * (encode_dim - 1))\n",
    "                               if encode_dim > 1 else cov_loss_val.item())\n",
    "    return weighted_loss.item(), step_errors, normalized_cov_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Table:\n",
      "       Environment  EncodeDim  WeightedError (CovReg off)  \\\n",
      "0  DampingPendulum          4                     0.00048   \n",
      "\n",
      "   WeightedError (CovReg on)  Diff_WeightedError  NormCovLoss (CovReg off)  \\\n",
      "0                   0.000417            0.000063                  0.023015   \n",
      "\n",
      "   NormCovLoss (CovReg on)  Diff_NormCovLoss  \n",
      "0             9.953190e-07          0.023014  \n",
      "Summary table saved to evaluation_summary.csv\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "envs = ['DampingPendulum']#['LogisticMap', 'DampingPendulum', 'Franka', 'DoublePendulum', 'Polynomial', 'G1', 'Go2']\n",
    "encode_dims = [4]#[4, 16, 64, 256, 1024]\n",
    "cov_regs = [0, 1]\n",
    "seeds = [1]#[1, 2, 3, 4, 5]\n",
    "\n",
    "best_models_dir = os.path.join(\"..\", \"log\", \"best_models\", project_name)\n",
    "results = {}\n",
    "\n",
    "pattern = r\"best_model_norm_(\\w+)_(\\d+)_(\\d+)_(\\d+)\\.pth\"\n",
    "all_files = glob.glob(os.path.join(best_models_dir, \"best_model_norm_*.pth\"))\n",
    "for f in all_files:\n",
    "    basename = os.path.basename(f)\n",
    "    m = re.match(pattern, basename)\n",
    "    if m:\n",
    "        env_name = m.group(1)\n",
    "        enc_dim = int(m.group(2))\n",
    "        cov_reg_val = int(m.group(3))\n",
    "        seed_val = int(m.group(4))\n",
    "        if enc_dim not in encode_dims or env_name not in envs or seed_val not in seeds:\n",
    "            continue\n",
    "        key = (env_name, enc_dim, cov_reg_val)\n",
    "        if key not in results:\n",
    "            results[key] = []\n",
    "        results[key].append((seed_val, f))\n",
    "\n",
    "agg_metrics = {}\n",
    "step_error_curves_agg = {}\n",
    "\n",
    "for env in envs:\n",
    "    Ksteps = 1 if env in [\"Polynomial\", \"LogisticMap\"] else 10\n",
    "\n",
    "    norm_str = \"norm\"\n",
    "    dataset_path = os.path.join(\"..\", \"data\", \"datasets\", \n",
    "                                f\"dataset_{env}_{norm_str}_Ktrain_60000_Kval_20000_Ktest_20000_Ksteps_{Ksteps}.pt\")\n",
    "    if not os.path.exists(dataset_path):\n",
    "        print(f\"Dataset file {dataset_path} not found for environment {env}, skipping.\")\n",
    "        continue\n",
    "    data_dict = torch.load(dataset_path, weights_only=False)\n",
    "    test_data = torch.from_numpy(data_dict[\"Ktest_data\"]).float().to(device)\n",
    "\n",
    "    if env in [\"Franka\", \"DoublePendulum\", \"DampingPendulum\", \"G1\", \"Go2\", \"Kinova\"]:\n",
    "        if env == \"Franka\":\n",
    "            u_dim = 7\n",
    "            state_dim = test_data.shape[2] - u_dim\n",
    "        elif env == \"DoublePendulum\":\n",
    "            u_dim = 2\n",
    "            state_dim = test_data.shape[2] - u_dim\n",
    "        elif env == \"DampingPendulum\":\n",
    "            u_dim = 1\n",
    "            state_dim = test_data.shape[2] - u_dim\n",
    "        elif env == \"G1\":\n",
    "            u_dim = 37\n",
    "            state_dim = test_data.shape[2] - u_dim\n",
    "        elif env == \"Go2\":\n",
    "            u_dim = 12\n",
    "            state_dim = test_data.shape[2] - u_dim\n",
    "        elif env == \"Kinova\":\n",
    "            u_dim = 7\n",
    "            state_dim = test_data.shape[2] - u_dim\n",
    "        else:\n",
    "            u_dim = None\n",
    "            state_dim = test_data.shape[2]\n",
    "    else:\n",
    "        u_dim = None\n",
    "        state_dim = test_data.shape[2]\n",
    "\n",
    "    for key in results:\n",
    "        if key[0] != env:\n",
    "            continue\n",
    "        enc_dim, cov_reg_val = key[1], key[2]\n",
    "        weighted_errors = []\n",
    "        norm_cov_losses = []\n",
    "        step_errors_all = []\n",
    "        for (seed_val, filepath) in results[key]:\n",
    "            checkpoint = torch.load(filepath, map_location=device)\n",
    "            layers = checkpoint['layer']\n",
    "            Nkoopman = state_dim + enc_dim\n",
    "            model = KoopmanNet(layers, Nkoopman, u_dim)\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            model.to(device)\n",
    "            w_err, step_errs, norm_cov_loss = evaluate_model(model, test_data, u_dim, gamma, state_dim, device)\n",
    "\n",
    "            weighted_errors.append(w_err)\n",
    "            norm_cov_losses.append(norm_cov_loss)\n",
    "            step_errors_all.append(np.array(step_errs))\n",
    "\n",
    "        weighted_errors = np.array(weighted_errors)\n",
    "        norm_cov_losses = np.array(norm_cov_losses)\n",
    "\n",
    "        weight_log = np.log(weighted_errors)\n",
    "        w_mean = np.exp(np.mean(weight_log))\n",
    "        w_std = np.exp(np.std(weight_log))\n",
    "        w_lower = np.exp(np.mean(weight_log) - np.std(weight_log))\n",
    "        w_upper = np.exp(np.mean(weight_log) + np.std(weight_log))\n",
    "        \n",
    "        cov_log = np.log(norm_cov_losses + 1e-12)\n",
    "        cov_mean = np.exp(np.mean(cov_log))\n",
    "        cov_std = np.exp(np.std(cov_log))\n",
    "        cov_lower = np.exp(np.mean(cov_log) - np.std(cov_log))\n",
    "        cov_upper = np.exp(np.mean(cov_log) + np.std(cov_log))\n",
    "        \n",
    "        step_errors_all = np.array(step_errors_all)\n",
    "\n",
    "        step_log = np.log(step_errors_all + 1e-12)\n",
    "        step_mean = np.exp(np.mean(step_log, axis=0))\n",
    "        step_std = np.exp(np.std(step_log, axis=0))\n",
    "        step_lower = np.exp(np.mean(step_log, axis=0) - np.std(step_log, axis=0))\n",
    "        step_upper = np.exp(np.mean(step_log, axis=0) + np.std(step_log, axis=0))\n",
    "        \n",
    "\n",
    "        agg_metrics[key] = {\n",
    "            \"WeightedError_mean\": w_mean,\n",
    "            \"WeightedError_lower\": w_lower,\n",
    "            \"WeightedError_upper\": w_upper,\n",
    "            \"NormalizedCovLoss_mean\": cov_mean,\n",
    "            \"NormalizedCovLoss_lower\": cov_lower,\n",
    "            \"NormalizedCovLoss_upper\": cov_upper\n",
    "        }\n",
    "        step_error_curves_agg[key] = {\n",
    "            \"mean\": step_mean,\n",
    "            \"lower\": step_lower,\n",
    "            \"upper\": step_upper\n",
    "        }\n",
    "\n",
    "rows = []\n",
    "\n",
    "for env in envs:\n",
    "    for enc_dim in encode_dims:\n",
    "        key0 = (env, enc_dim, 0)\n",
    "        key1 = (env, enc_dim, 1)\n",
    "        if key0 in agg_metrics and key1 in agg_metrics:\n",
    "            diff_weight = agg_metrics[key0][\"WeightedError_mean\"] - agg_metrics[key1][\"WeightedError_mean\"]\n",
    "            diff_cov = agg_metrics[key0][\"NormalizedCovLoss_mean\"] - agg_metrics[key1][\"NormalizedCovLoss_mean\"]\n",
    "            rows.append({\n",
    "                \"Environment\": env,\n",
    "                \"EncodeDim\": enc_dim,\n",
    "                \"WeightedError (CovReg off)\": agg_metrics[key0][\"WeightedError_mean\"],\n",
    "                \"WeightedError (CovReg on)\": agg_metrics[key1][\"WeightedError_mean\"],\n",
    "                \"Diff_WeightedError\": diff_weight,\n",
    "                \"NormCovLoss (CovReg off)\": agg_metrics[key0][\"NormalizedCovLoss_mean\"],\n",
    "                \"NormCovLoss (CovReg on)\": agg_metrics[key1][\"NormalizedCovLoss_mean\"],\n",
    "                \"Diff_NormCovLoss\": diff_cov\n",
    "            })\n",
    "        else:\n",
    "            for cov in cov_regs:\n",
    "                key = (env, enc_dim, cov)\n",
    "                if key in agg_metrics:\n",
    "                    rows.append({\n",
    "                        \"Environment\": env,\n",
    "                        \"EncodeDim\": enc_dim,\n",
    "                        \"WeightedError (CovReg off)\" if cov==0 else \"WeightedError (CovReg on)\": agg_metrics[key][\"WeightedError_mean\"],\n",
    "                        \"Diff_WeightedError\": np.nan,\n",
    "                        \"NormCovLoss (CovReg off)\" if cov==0 else \"NormCovLoss (CovReg on)\": agg_metrics[key][\"NormalizedCovLoss_mean\"],\n",
    "                        \"Diff_NormCovLoss\": np.nan\n",
    "                    })\n",
    "\n",
    "df_summary = pd.DataFrame(rows)\n",
    "print(\"Summary Table:\")\n",
    "print(df_summary)\n",
    "table_csv_path = \"evaluation_summary.csv\"\n",
    "df_summary.to_csv(table_csv_path, index=False)\n",
    "print(f\"Summary table saved to {table_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot: Koopman_Results_Apr_8_2/DampingPendulum/MultiStepError_DampingPendulum.png\n",
      "Saved plot: Koopman_Results_Apr_8_2/DampingPendulum/NormalizedCovLoss_DampingPendulum.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1429263/3815865275.py:88: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap('tab10', len(encode_dims))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot: Koopman_Results_Apr_8_2/DampingPendulum/MultiStepLossCurves_DampingPendulum.png\n"
     ]
    }
   ],
   "source": [
    "# Plot 1: Average Multi-step Prediction Error vs. Encode Dimension\n",
    "for env in envs:\n",
    "    out_dir = os.path.join(project_name, env)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for cov_reg_val in cov_regs:\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        lower_bounds = []\n",
    "        upper_bounds = []\n",
    "        for key, metrics in agg_metrics.items():\n",
    "            if key[0] == env and key[2] == cov_reg_val:\n",
    "                x_vals.append(key[1])\n",
    "                y_vals.append(metrics[\"WeightedError_mean\"])\n",
    "                lower_bounds.append(metrics[\"WeightedError_lower\"])\n",
    "                upper_bounds.append(metrics[\"WeightedError_upper\"])\n",
    "        if len(x_vals) == 0:\n",
    "            continue\n",
    "\n",
    "        order = np.argsort(x_vals)\n",
    "        x_vals = np.array(x_vals)[order]\n",
    "        y_vals = np.array(y_vals)[order]\n",
    "        lower_bounds = np.array(lower_bounds)[order]\n",
    "        upper_bounds = np.array(upper_bounds)[order]\n",
    "        label = f\"CovReg {'on' if cov_reg_val==1 else 'off'}\"\n",
    "        plt.plot(x_vals, y_vals, marker='o', label=label)\n",
    "        plt.fill_between(x_vals, lower_bounds, upper_bounds, alpha=0.3)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Encode Dimension (log scale)\")\n",
    "    plt.ylabel(\"Average Multi-step Prediction Error (MSE, log scale)\")\n",
    "    plt.title(f\"Multi-step Prediction Error vs. Encode Dimension for {env}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(out_dir, f\"AverageMultiStepError_{env}.png\")\n",
    "    plt.savefig(fig_path, dpi=300)\n",
    "    print(f\"Saved plot: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# Plot 2: Normalized Covariance Loss vs. Encode Dimension\n",
    "for env in envs:\n",
    "    out_dir = os.path.join(project_name, env)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for cov_reg_val in cov_regs:\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        lower_bounds = []\n",
    "        upper_bounds = []\n",
    "        for key, metrics in agg_metrics.items():\n",
    "            if key[0] == env and key[2] == cov_reg_val:\n",
    "                x_vals.append(key[1])\n",
    "                y_vals.append(metrics[\"NormalizedCovLoss_mean\"])\n",
    "                lower_bounds.append(metrics[\"NormalizedCovLoss_lower\"])\n",
    "                upper_bounds.append(metrics[\"NormalizedCovLoss_upper\"])\n",
    "        if len(x_vals) == 0:\n",
    "            continue\n",
    "        order = np.argsort(x_vals)\n",
    "        x_vals = np.array(x_vals)[order]\n",
    "        y_vals = np.array(y_vals)[order]\n",
    "        lower_bounds = np.array(lower_bounds)[order]\n",
    "        upper_bounds = np.array(upper_bounds)[order]\n",
    "        label = f\"CovReg {'on' if cov_reg_val==1 else 'off'}\"\n",
    "        plt.plot(x_vals, y_vals, marker='o', label=label)\n",
    "        plt.fill_between(x_vals, lower_bounds, upper_bounds, alpha=0.3)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Encode Dimension (log scale)\")\n",
    "    plt.ylabel(\"Normalized Covariance Loss (log scale)\")\n",
    "    plt.title(f\"Normalized Covariance Loss vs. Encode Dimension for {env}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(out_dir, f\"NormalizedCovLoss_{env}.png\")\n",
    "    plt.savefig(fig_path, dpi=300)\n",
    "    print(f\"Saved plot: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# Plot 3: Multi-step Loss Curves for each environment\n",
    "for env in envs:\n",
    "    if env == \"LogisticMap\" or env == \"Polynomial\":\n",
    "        continue\n",
    "    out_dir = os.path.join(project_name, env)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    cmap = cm.get_cmap('tab10', len(encode_dims))\n",
    "\n",
    "    dimension_handles = []\n",
    "    covreg_handles = []\n",
    "    \n",
    "    for i, enc_dim in enumerate(encode_dims):\n",
    "        color = cmap(i)\n",
    "\n",
    "        dimension_handles.append(\n",
    "            mlines.Line2D([], [], color=color, marker='o', linestyle='-', \n",
    "                          label=f'{enc_dim}')\n",
    "        )\n",
    "        \n",
    "        for cov_reg_val in cov_regs:\n",
    "            key = (env, enc_dim, cov_reg_val)\n",
    "            if key in step_error_curves_agg:\n",
    "                steps = np.arange(1, len(step_error_curves_agg[key][\"mean\"]) + 1)\n",
    "                mean_curve = step_error_curves_agg[key][\"mean\"]\n",
    "                #lower_curve = step_error_curves_agg[key][\"lower\"]\n",
    "                #upper_curve = step_error_curves_agg[key][\"upper\"]\n",
    "                \n",
    "                linestyle = '-' if cov_reg_val == 0 else '--'\n",
    "\n",
    "                ax.plot(\n",
    "                    steps, mean_curve, marker='o', color=color, linestyle=linestyle\n",
    "                )\n",
    "                #ax.fill_between(steps, lower_curve, upper_curve, color=color, alpha=0.3)\n",
    "    \n",
    "    cov_off_line = mlines.Line2D([], [], color='black', marker='', linestyle='-',\n",
    "                                 label='Off')\n",
    "    cov_on_line = mlines.Line2D([], [], color='black', marker='', linestyle='--',\n",
    "                                label='On')\n",
    "    covreg_handles.extend([cov_off_line, cov_on_line])\n",
    "\n",
    "    legend1 = ax.legend(handles=dimension_handles, loc='upper left', bbox_to_anchor=(0, 1),\n",
    "                        title='Encode Dimension', frameon=True)\n",
    "    ax.add_artist(legend1)\n",
    "\n",
    "    legend2 = ax.legend(handles=covreg_handles, loc='upper left', bbox_to_anchor=(0.17, 1),\n",
    "                        title='Covariance Loss', frameon=True)\n",
    "    ax.add_artist(legend2)\n",
    "\n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.set_ylabel(\"Prediction Error (MSE, log scale)\")\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_title(f\"Multi-step Error Curves for {env}\")\n",
    "    ax.grid(True, which=\"both\", ls=\"--\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    fig_path = os.path.join(out_dir, f\"MultiStepError_{env}.png\")\n",
    "    plt.savefig(fig_path, dpi=300)\n",
    "    print(f\"Saved plot: {fig_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koopman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

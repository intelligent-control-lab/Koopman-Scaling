{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c0fd023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing m=50...\n",
      "Processing m=100...\n",
      "Processing m=200...\n",
      "✅ Saved figure to: ./latent_cov_heatmaps/Polynomial_m_sweep_heatmap.pdf\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Paths / imports\n",
    "# ---------------------------------------------------------------------\n",
    "sys.path.append(\"../utility\")\n",
    "\n",
    "from network import KoopmanNet\n",
    "from dataset import KoopmanDatasetCollector\n",
    "\n",
    "LOG_CSV = os.path.join(\"..\", \"log\", \"Sep_21\", \"koopman_results_log.csv\")\n",
    "\n",
    "TARGET_ENV = \"Polynomial\"\n",
    "TARGET_ENCODE_DIM = 48\n",
    "TARGET_TRAIN_SAMPLES = 140000\n",
    "TARGET_M_VALUES = [50, 100, 200]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Matplotlib settings (Updated for larger fonts)\n",
    "# ---------------------------------------------------------------------\n",
    "mpl.rcParams.update({\n",
    "    \"figure.dpi\": 150,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"figure.constrained_layout.use\": True,\n",
    "    # Increased font sizes\n",
    "    \"font.size\": 12,\n",
    "    \"axes.titlesize\": 18,     # Big headers for columns\n",
    "    \"axes.labelsize\": 14,     # Big labels for axes\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"lines.linewidth\": 1.5,\n",
    "    \"axes.formatter.use_mathtext\": True,\n",
    "    \"pdf.fonttype\": 42,\n",
    "    \"ps.fonttype\": 42,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times New Roman\", \"Times\", \"DejaVu Serif\"],\n",
    "})\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# ---------------------------------------------------------------------\n",
    "def build_layers_from_row(row: pd.Series) -> list[int]:\n",
    "    state_dim = int(row[\"state_dim\"])\n",
    "    encode_dim = int(row[\"encode_dim\"])\n",
    "    hidden_layers = int(row[\"hidden_layers\"])\n",
    "    hidden_dim = int(row[\"hidden_dim\"])\n",
    "\n",
    "    layers = [state_dim]\n",
    "    for _ in range(hidden_layers):\n",
    "        layers.append(hidden_dim)\n",
    "    layers.append(encode_dim)\n",
    "    return layers\n",
    "\n",
    "def build_model_from_row(row: pd.Series, device: str = \"cpu\"):\n",
    "    state_dim = int(row[\"state_dim\"])\n",
    "    encode_dim = int(row[\"encode_dim\"])\n",
    "    Nkoopman = state_dim + encode_dim\n",
    "\n",
    "    u_dim_raw = row[\"u_dim\"]\n",
    "    u_dim = None if (pd.isna(u_dim_raw) or u_dim_raw is None) else int(u_dim_raw)\n",
    "\n",
    "    use_residual = bool(row[\"use_residual\"])\n",
    "    layers = build_layers_from_row(row)\n",
    "\n",
    "    model = KoopmanNet(layers, Nkoopman, u_dim, use_residual=use_residual).to(device)\n",
    "\n",
    "    ckpt_path = row[\"model_path\"]\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    if \"model\" not in ckpt:\n",
    "        raise KeyError(f\"'model' key not in checkpoint: {ckpt_path}\")\n",
    "\n",
    "    state_dict = ckpt[\"model\"]\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model, Nkoopman, u_dim, state_dim\n",
    "\n",
    "def cov_of_latent_z(model: nn.Module,\n",
    "                    data_tensor: torch.Tensor,\n",
    "                    state_dim: int,\n",
    "                    u_dim: int | None,\n",
    "                    device: str = \"cpu\") -> np.ndarray:\n",
    "    data = data_tensor.to(device)\n",
    "    steps, traj_num, N = data.shape\n",
    "\n",
    "    if u_dim is None:\n",
    "        X0 = data[0, :, :]\n",
    "        encoded = model.encode(X0)\n",
    "    else:\n",
    "        X0 = data[0, :, u_dim:]\n",
    "        encoded = model.encode(X0)\n",
    "\n",
    "    z = encoded[:, state_dim:]\n",
    "    z_mean = z.mean(dim=0, keepdim=True)\n",
    "    z_centered = z - z_mean\n",
    "    cov = (z_centered.T @ z_centered) / (z_centered.size(0) - 1)\n",
    "    return cov.detach().cpu().numpy()\n",
    "\n",
    "def covariance_to_correlation(cov: np.ndarray, eps: float = 1e-8) -> np.ndarray:\n",
    "    d = np.sqrt(np.diag(cov) + eps)\n",
    "    denom = np.outer(d, d) + eps\n",
    "    return cov / denom\n",
    "\n",
    "def average_mats(mats: list[np.ndarray]) -> np.ndarray:\n",
    "    return np.mean(np.stack(mats, axis=0), axis=0)\n",
    "\n",
    "def mask_diag(mat: np.ndarray) -> np.ndarray:\n",
    "    m = mat.copy()\n",
    "    np.fill_diagonal(m, 0.0)\n",
    "    return m\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Main\n",
    "# ---------------------------------------------------------------------\n",
    "def main():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    assert os.path.exists(LOG_CSV), f\"CSV log not found: {LOG_CSV}\"\n",
    "    log = pd.read_csv(LOG_CSV)\n",
    "\n",
    "    df = log[\n",
    "        (log[\"env_name\"] == TARGET_ENV)\n",
    "        & (log[\"encode_dim\"] == TARGET_ENCODE_DIM)\n",
    "        & (log[\"train_samples\"] == TARGET_TRAIN_SAMPLES)\n",
    "    ].copy()\n",
    "    assert not df.empty, \"Filtered dataframe is empty.\"\n",
    "\n",
    "    df[\"use_covariance_loss\"] = df[\"use_covariance_loss\"].astype(bool)\n",
    "    grouped = df.groupby([\"m\", \"use_covariance_loss\"])\n",
    "\n",
    "    latent_corr = {}\n",
    "\n",
    "    for m_value in TARGET_M_VALUES:\n",
    "        if (m_value, False) not in grouped.groups or (m_value, True) not in grouped.groups:\n",
    "            continue\n",
    "\n",
    "        group_no_cov = grouped.get_group((m_value, False))\n",
    "        group_with_cov = grouped.get_group((m_value, True))\n",
    "\n",
    "        print(f\"Processing m={m_value}...\")\n",
    "\n",
    "        data_collector = KoopmanDatasetCollector(\n",
    "            TARGET_ENV, TARGET_TRAIN_SAMPLES, 20000, 20000,\n",
    "            Ksteps=1, normalize=False, m=m_value,\n",
    "        )\n",
    "        _, _, Ktest_data_np = data_collector.get_data()\n",
    "        Ktest_data = torch.from_numpy(Ktest_data_np).float()\n",
    "        state_dim_ds = data_collector.state_dim\n",
    "        u_dim_ds = data_collector.u_dim\n",
    "\n",
    "        # --- no cov ---\n",
    "        covs = []\n",
    "        for _, row in group_no_cov.iterrows():\n",
    "            model, _, u_dim_r, _ = build_model_from_row(row, device=device)\n",
    "            cov = cov_of_latent_z(model, Ktest_data, state_dim_ds, u_dim_ds, device=device)\n",
    "            covs.append(cov)\n",
    "        latent_corr[(m_value, False)] = covariance_to_correlation(average_mats(covs))\n",
    "\n",
    "        # --- with cov ---\n",
    "        covs = []\n",
    "        for _, row in group_with_cov.iterrows():\n",
    "            model, _, u_dim_r, _ = build_model_from_row(row, device=device)\n",
    "            cov = cov_of_latent_z(model, Ktest_data, state_dim_ds, u_dim_ds, device=device)\n",
    "            covs.append(cov)\n",
    "        latent_corr[(m_value, True)] = covariance_to_correlation(average_mats(covs))\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # Plotting\n",
    "    # -----------------------------------------------------------------\n",
    "    mats_for_scale = [mask_diag(v) for v in latent_corr.values()]\n",
    "    vmax = max(np.abs(m).max() for m in mats_for_scale) if mats_for_scale else 1.0\n",
    "    vmax = max(vmax, 1e-3)\n",
    "    vmin = -vmax\n",
    "\n",
    "    # Increased figure size slightly to accommodate larger fonts\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(10, 6), constrained_layout=True)\n",
    "\n",
    "    for col, m_value in enumerate(TARGET_M_VALUES):\n",
    "        for row, use_cov in enumerate([False, True]):\n",
    "            ax = axes[row, col]\n",
    "            mat = latent_corr.get((m_value, use_cov), None)\n",
    "            \n",
    "            if mat is None:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            mat_plot = mask_diag(mat)\n",
    "            im = ax.imshow(mat_plot, vmin=vmin, vmax=vmax, cmap=\"coolwarm\")\n",
    "\n",
    "            # --- REDUCE REPETITIVE LABELS ---\n",
    "            \n",
    "            # 1. Column Headers (Only on top row)\n",
    "            if row == 0:\n",
    "                ax.set_title(f\"$m = {m_value}$\")\n",
    "            \n",
    "            # 2. Row Labels (Only on left column)\n",
    "            if col == 0:\n",
    "                label = \"Without $\\mathcal{L}_{cov}$\" if not use_cov else \"With $\\mathcal{L}_{cov}$\"\n",
    "                ax.set_ylabel(f\"{label}\\nLatent Index\")\n",
    "            else:\n",
    "                ax.set_ylabel(\"\")\n",
    "                # Hide y-ticks on internal plots for cleaner look\n",
    "                ax.set_yticks([]) \n",
    "\n",
    "            # 3. X Labels (Only on bottom row)\n",
    "            if row == 1:\n",
    "                ax.set_xlabel(\"Latent Index\")\n",
    "            else:\n",
    "                ax.set_xlabel(\"\")\n",
    "                # Hide x-ticks on top row\n",
    "                ax.set_xticks([])\n",
    "\n",
    "    # Colorbar\n",
    "    cbar = fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.8, aspect=30)\n",
    "    cbar.set_label(\"Correlation (off-diagonal)\", fontsize=14)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "    out_dir = \"./latent_cov_heatmaps\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    pdf_path = os.path.join(out_dir, \"Polynomial_m_sweep_heatmap.pdf\")\n",
    "    \n",
    "    fig.savefig(pdf_path, bbox_inches=\"tight\")\n",
    "    print(\"✅ Saved figure to:\", pdf_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f5a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koopman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c0fd023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing m=50...\n",
      "Processing m=100...\n",
      "Processing m=200...\n",
      "✅ Saved figure to: ./latent_cov_heatmaps/Polynomial_m_sweep_heatmap.pdf\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Paths / imports\n",
    "# ---------------------------------------------------------------------\n",
    "sys.path.append(\"../utility\")\n",
    "\n",
    "from network import KoopmanNet\n",
    "from dataset import KoopmanDatasetCollector\n",
    "\n",
    "LOG_CSV = os.path.join(\"..\", \"log\", \"Sep_21\", \"koopman_results_log.csv\")\n",
    "\n",
    "TARGET_ENV = \"Polynomial\"\n",
    "TARGET_ENCODE_DIM = 48\n",
    "TARGET_TRAIN_SAMPLES = 140000\n",
    "TARGET_M_VALUES = [50, 100, 200]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Matplotlib settings (Updated for larger fonts)\n",
    "# ---------------------------------------------------------------------\n",
    "mpl.rcParams.update({\n",
    "    \"figure.dpi\": 150,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"figure.constrained_layout.use\": True,\n",
    "    # Increased font sizes\n",
    "    \"font.size\": 12,\n",
    "    \"axes.titlesize\": 18,     # Big headers for columns\n",
    "    \"axes.labelsize\": 14,     # Big labels for axes\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"lines.linewidth\": 1.5,\n",
    "    \"axes.formatter.use_mathtext\": True,\n",
    "    \"pdf.fonttype\": 42,\n",
    "    \"ps.fonttype\": 42,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times New Roman\", \"Times\", \"DejaVu Serif\"],\n",
    "})\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# ---------------------------------------------------------------------\n",
    "def build_layers_from_row(row: pd.Series) -> list[int]:\n",
    "    state_dim = int(row[\"state_dim\"])\n",
    "    encode_dim = int(row[\"encode_dim\"])\n",
    "    hidden_layers = int(row[\"hidden_layers\"])\n",
    "    hidden_dim = int(row[\"hidden_dim\"])\n",
    "\n",
    "    layers = [state_dim]\n",
    "    for _ in range(hidden_layers):\n",
    "        layers.append(hidden_dim)\n",
    "    layers.append(encode_dim)\n",
    "    return layers\n",
    "\n",
    "def build_model_from_row(row: pd.Series, device: str = \"cpu\"):\n",
    "    state_dim = int(row[\"state_dim\"])\n",
    "    encode_dim = int(row[\"encode_dim\"])\n",
    "    Nkoopman = state_dim + encode_dim\n",
    "\n",
    "    u_dim_raw = row[\"u_dim\"]\n",
    "    u_dim = None if (pd.isna(u_dim_raw) or u_dim_raw is None) else int(u_dim_raw)\n",
    "\n",
    "    use_residual = bool(row[\"use_residual\"])\n",
    "    layers = build_layers_from_row(row)\n",
    "\n",
    "    model = KoopmanNet(layers, Nkoopman, u_dim, use_residual=use_residual).to(device)\n",
    "\n",
    "    ckpt_path = row[\"model_path\"]\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    if \"model\" not in ckpt:\n",
    "        raise KeyError(f\"'model' key not in checkpoint: {ckpt_path}\")\n",
    "\n",
    "    state_dict = ckpt[\"model\"]\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model, Nkoopman, u_dim, state_dim\n",
    "\n",
    "def cov_of_latent_z(model: nn.Module,\n",
    "                    data_tensor: torch.Tensor,\n",
    "                    state_dim: int,\n",
    "                    u_dim: int | None,\n",
    "                    device: str = \"cpu\") -> np.ndarray:\n",
    "    data = data_tensor.to(device)\n",
    "    steps, traj_num, N = data.shape\n",
    "\n",
    "    if u_dim is None:\n",
    "        X0 = data[0, :, :]\n",
    "        encoded = model.encode(X0)\n",
    "    else:\n",
    "        X0 = data[0, :, u_dim:]\n",
    "        encoded = model.encode(X0)\n",
    "\n",
    "    z = encoded[:, state_dim:]\n",
    "    z_mean = z.mean(dim=0, keepdim=True)\n",
    "    z_centered = z - z_mean\n",
    "    cov = (z_centered.T @ z_centered) / (z_centered.size(0) - 1)\n",
    "    return cov.detach().cpu().numpy()\n",
    "\n",
    "def covariance_to_correlation(cov: np.ndarray, eps: float = 1e-8) -> np.ndarray:\n",
    "    d = np.sqrt(np.diag(cov) + eps)\n",
    "    denom = np.outer(d, d) + eps\n",
    "    return cov / denom\n",
    "\n",
    "def average_mats(mats: list[np.ndarray]) -> np.ndarray:\n",
    "    return np.mean(np.stack(mats, axis=0), axis=0)\n",
    "\n",
    "def mask_diag(mat: np.ndarray) -> np.ndarray:\n",
    "    m = mat.copy()\n",
    "    np.fill_diagonal(m, 0.0)\n",
    "    return m\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Main\n",
    "# ---------------------------------------------------------------------\n",
    "def main():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    assert os.path.exists(LOG_CSV), f\"CSV log not found: {LOG_CSV}\"\n",
    "    log = pd.read_csv(LOG_CSV)\n",
    "\n",
    "    df = log[\n",
    "        (log[\"env_name\"] == TARGET_ENV)\n",
    "        & (log[\"encode_dim\"] == TARGET_ENCODE_DIM)\n",
    "        & (log[\"train_samples\"] == TARGET_TRAIN_SAMPLES)\n",
    "    ].copy()\n",
    "    assert not df.empty, \"Filtered dataframe is empty.\"\n",
    "\n",
    "    df[\"use_covariance_loss\"] = df[\"use_covariance_loss\"].astype(bool)\n",
    "    grouped = df.groupby([\"m\", \"use_covariance_loss\"])\n",
    "\n",
    "    latent_corr = {}\n",
    "\n",
    "    for m_value in TARGET_M_VALUES:\n",
    "        if (m_value, False) not in grouped.groups or (m_value, True) not in grouped.groups:\n",
    "            continue\n",
    "\n",
    "        group_no_cov = grouped.get_group((m_value, False))\n",
    "        group_with_cov = grouped.get_group((m_value, True))\n",
    "\n",
    "        print(f\"Processing m={m_value}...\")\n",
    "\n",
    "        data_collector = KoopmanDatasetCollector(\n",
    "            TARGET_ENV, TARGET_TRAIN_SAMPLES, 20000, 20000,\n",
    "            Ksteps=1, normalize=False, m=m_value,\n",
    "        )\n",
    "        _, _, Ktest_data_np = data_collector.get_data()\n",
    "        Ktest_data = torch.from_numpy(Ktest_data_np).float()\n",
    "        state_dim_ds = data_collector.state_dim\n",
    "        u_dim_ds = data_collector.u_dim\n",
    "\n",
    "        # --- no cov ---\n",
    "        covs = []\n",
    "        for _, row in group_no_cov.iterrows():\n",
    "            model, _, u_dim_r, _ = build_model_from_row(row, device=device)\n",
    "            cov = cov_of_latent_z(model, Ktest_data, state_dim_ds, u_dim_ds, device=device)\n",
    "            covs.append(cov)\n",
    "        latent_corr[(m_value, False)] = covariance_to_correlation(average_mats(covs))\n",
    "\n",
    "        # --- with cov ---\n",
    "        covs = []\n",
    "        for _, row in group_with_cov.iterrows():\n",
    "            model, _, u_dim_r, _ = build_model_from_row(row, device=device)\n",
    "            cov = cov_of_latent_z(model, Ktest_data, state_dim_ds, u_dim_ds, device=device)\n",
    "            covs.append(cov)\n",
    "        latent_corr[(m_value, True)] = covariance_to_correlation(average_mats(covs))\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # Plotting\n",
    "    # -----------------------------------------------------------------\n",
    "    mats_for_scale = [mask_diag(v) for v in latent_corr.values()]\n",
    "    vmax = max(np.abs(m).max() for m in mats_for_scale) if mats_for_scale else 1.0\n",
    "    vmax = max(vmax, 1e-3)\n",
    "    vmin = -vmax\n",
    "\n",
    "    # Increased figure size slightly to accommodate larger fonts\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(10, 6), constrained_layout=True)\n",
    "\n",
    "    for col, m_value in enumerate(TARGET_M_VALUES):\n",
    "        for row, use_cov in enumerate([False, True]):\n",
    "            ax = axes[row, col]\n",
    "            mat = latent_corr.get((m_value, use_cov), None)\n",
    "            \n",
    "            if mat is None:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            mat_plot = mask_diag(mat)\n",
    "            im = ax.imshow(mat_plot, vmin=vmin, vmax=vmax, cmap=\"coolwarm\")\n",
    "\n",
    "            # --- REDUCE REPETITIVE LABELS ---\n",
    "            \n",
    "            # 1. Column Headers (Only on top row)\n",
    "            if row == 0:\n",
    "                ax.set_title(f\"$m = {m_value}$\")\n",
    "            \n",
    "            # 2. Row Labels (Only on left column)\n",
    "            if col == 0:\n",
    "                label = \"Without $\\mathcal{L}_{cov}$\" if not use_cov else \"With $\\mathcal{L}_{cov}$\"\n",
    "                ax.set_ylabel(f\"{label}\\nLatent Index\")\n",
    "            else:\n",
    "                ax.set_ylabel(\"\")\n",
    "                # Hide y-ticks on internal plots for cleaner look\n",
    "                ax.set_yticks([]) \n",
    "\n",
    "            # 3. X Labels (Only on bottom row)\n",
    "            if row == 1:\n",
    "                ax.set_xlabel(\"Latent Index\")\n",
    "            else:\n",
    "                ax.set_xlabel(\"\")\n",
    "                # Hide x-ticks on top row\n",
    "                ax.set_xticks([])\n",
    "\n",
    "    # Colorbar\n",
    "    cbar = fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.8, aspect=30)\n",
    "    cbar.set_label(\"Correlation (off-diagonal)\", fontsize=14)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "    out_dir = \"./latent_cov_heatmaps\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    pdf_path = os.path.join(out_dir, \"Polynomial_m_sweep_heatmap.pdf\")\n",
    "    \n",
    "    fig.savefig(pdf_path, bbox_inches=\"tight\")\n",
    "    print(\"✅ Saved figure to:\", pdf_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73f5a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Jan 29 2025 23:16:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing m=50...\n",
      "Processing m=100...\n",
      "Processing m=200...\n",
      "\n",
      "=== Quantitative covariance-sparsity metric (OFF-DIAGONAL) ===\n",
      "Threshold: |cov_ij| < 0.001\n",
      "m= 50 | no cov-loss: 154/2256 (6.83%) | with cov-loss: 1004/2256 (44.50%) | Δ=37.68%\n",
      "m=100 | no cov-loss: 22/2256 (0.98%) | with cov-loss: 440/2256 (19.50%) | Δ=18.53%\n",
      "m=200 | no cov-loss: 4/2256 (0.18%) | with cov-loss: 244/2256 (10.82%) | Δ=10.64%\n",
      "\n",
      "✅ Saved figure to: ./latent_cov_heatmaps/Polynomial_m_sweep_heatmap.pdf\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Paths / imports\n",
    "# ---------------------------------------------------------------------\n",
    "sys.path.append(\"../utility\")\n",
    "\n",
    "from network import KoopmanNet\n",
    "from dataset import KoopmanDatasetCollector\n",
    "\n",
    "LOG_CSV = os.path.join(\"..\", \"log\", \"Sep_21\", \"koopman_results_log.csv\")\n",
    "\n",
    "TARGET_ENV = \"Polynomial\"\n",
    "TARGET_ENCODE_DIM = 48\n",
    "TARGET_TRAIN_SAMPLES = 140000\n",
    "TARGET_M_VALUES = [50, 100, 200]\n",
    "\n",
    "# Quantitative metric threshold (covariance magnitude)\n",
    "# Counts how many OFF-DIAGONAL entries satisfy |cov_ij| < COV_THRESHOLD\n",
    "COV_THRESHOLD = 1e-3\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Matplotlib settings (Updated for larger fonts)\n",
    "# ---------------------------------------------------------------------\n",
    "mpl.rcParams.update({\n",
    "    \"figure.dpi\": 150,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"figure.constrained_layout.use\": True,\n",
    "    \"font.size\": 12,\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"lines.linewidth\": 1.5,\n",
    "    \"axes.formatter.use_mathtext\": True,\n",
    "    \"pdf.fonttype\": 42,\n",
    "    \"ps.fonttype\": 42,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times New Roman\", \"Times\", \"DejaVu Serif\"],\n",
    "})\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# ---------------------------------------------------------------------\n",
    "def build_layers_from_row(row: pd.Series) -> list[int]:\n",
    "    state_dim = int(row[\"state_dim\"])\n",
    "    encode_dim = int(row[\"encode_dim\"])\n",
    "    hidden_layers = int(row[\"hidden_layers\"])\n",
    "    hidden_dim = int(row[\"hidden_dim\"])\n",
    "\n",
    "    layers = [state_dim]\n",
    "    for _ in range(hidden_layers):\n",
    "        layers.append(hidden_dim)\n",
    "    layers.append(encode_dim)\n",
    "    return layers\n",
    "\n",
    "def build_model_from_row(row: pd.Series, device: str = \"cpu\"):\n",
    "    state_dim = int(row[\"state_dim\"])\n",
    "    encode_dim = int(row[\"encode_dim\"])\n",
    "    Nkoopman = state_dim + encode_dim\n",
    "\n",
    "    u_dim_raw = row[\"u_dim\"]\n",
    "    u_dim = None if (pd.isna(u_dim_raw) or u_dim_raw is None) else int(u_dim_raw)\n",
    "\n",
    "    use_residual = bool(row[\"use_residual\"])\n",
    "    layers = build_layers_from_row(row)\n",
    "\n",
    "    model = KoopmanNet(layers, Nkoopman, u_dim, use_residual=use_residual).to(device)\n",
    "\n",
    "    ckpt_path = row[\"model_path\"]\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    if \"model\" not in ckpt:\n",
    "        raise KeyError(f\"'model' key not in checkpoint: {ckpt_path}\")\n",
    "\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    model.eval()\n",
    "    return model, Nkoopman, u_dim, state_dim\n",
    "\n",
    "@torch.no_grad()\n",
    "def cov_of_latent_z(model: nn.Module,\n",
    "                    data_tensor: torch.Tensor,\n",
    "                    state_dim: int,\n",
    "                    u_dim: int | None,\n",
    "                    device: str = \"cpu\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns covariance of the latent part z (shape: encode_dim x encode_dim),\n",
    "    computed from encoded initial states across trajectories.\n",
    "    \"\"\"\n",
    "    data = data_tensor.to(device)\n",
    "    steps, traj_num, N = data.shape\n",
    "\n",
    "    if u_dim is None:\n",
    "        X0 = data[0, :, :]\n",
    "        encoded = model.encode(X0)\n",
    "    else:\n",
    "        X0 = data[0, :, u_dim:]\n",
    "        encoded = model.encode(X0)\n",
    "\n",
    "    z = encoded[:, state_dim:]  # latent-only (encode_dim)\n",
    "    z_centered = z - z.mean(dim=0, keepdim=True)\n",
    "    cov = (z_centered.T @ z_centered) / (z_centered.size(0) - 1)\n",
    "    return cov.detach().cpu().numpy()\n",
    "\n",
    "def covariance_to_correlation(cov: np.ndarray, eps: float = 1e-8) -> np.ndarray:\n",
    "    d = np.sqrt(np.diag(cov) + eps)\n",
    "    denom = np.outer(d, d) + eps\n",
    "    return cov / denom\n",
    "\n",
    "def average_mats(mats: list[np.ndarray]) -> np.ndarray:\n",
    "    return np.mean(np.stack(mats, axis=0), axis=0)\n",
    "\n",
    "def count_small_offdiag_cov(cov: np.ndarray, thresh: float) -> tuple[int, int, float]:\n",
    "    \"\"\"\n",
    "    Counts OFF-DIAGONAL entries with |cov_ij| < thresh.\n",
    "    Returns: (count, total_offdiag, fraction)\n",
    "    \"\"\"\n",
    "    if cov.ndim != 2 or cov.shape[0] != cov.shape[1]:\n",
    "        raise ValueError(f\"cov must be square 2D array, got shape {cov.shape}\")\n",
    "    n = cov.shape[0]\n",
    "    off_mask = ~np.eye(n, dtype=bool)\n",
    "    vals = np.abs(cov[off_mask])\n",
    "    total = vals.size\n",
    "    cnt = int(np.sum(vals < thresh))\n",
    "    frac = float(cnt / total) if total > 0 else 0.0\n",
    "    return cnt, total, frac\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Main\n",
    "# ---------------------------------------------------------------------\n",
    "def main():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    assert os.path.exists(LOG_CSV), f\"CSV log not found: {LOG_CSV}\"\n",
    "    log = pd.read_csv(LOG_CSV)\n",
    "\n",
    "    df = log[\n",
    "        (log[\"env_name\"] == TARGET_ENV)\n",
    "        & (log[\"encode_dim\"] == TARGET_ENCODE_DIM)\n",
    "        & (log[\"train_samples\"] == TARGET_TRAIN_SAMPLES)\n",
    "    ].copy()\n",
    "    assert not df.empty, \"Filtered dataframe is empty.\"\n",
    "\n",
    "    df[\"use_covariance_loss\"] = df[\"use_covariance_loss\"].astype(bool)\n",
    "    grouped = df.groupby([\"m\", \"use_covariance_loss\"])\n",
    "\n",
    "    # Store BOTH covariance and correlation\n",
    "    latent_cov: dict[tuple[int, bool], np.ndarray] = {}\n",
    "    latent_corr: dict[tuple[int, bool], np.ndarray] = {}\n",
    "    cov_small_stats: dict[tuple[int, bool], tuple[int, int, float]] = {}\n",
    "\n",
    "    for m_value in TARGET_M_VALUES:\n",
    "        if (m_value, False) not in grouped.groups or (m_value, True) not in grouped.groups:\n",
    "            print(f\"Skipping m={m_value} (missing with/without cov-loss runs).\")\n",
    "            continue\n",
    "\n",
    "        group_no_cov = grouped.get_group((m_value, False))\n",
    "        group_with_cov = grouped.get_group((m_value, True))\n",
    "\n",
    "        print(f\"Processing m={m_value}...\")\n",
    "\n",
    "        data_collector = KoopmanDatasetCollector(\n",
    "            TARGET_ENV, TARGET_TRAIN_SAMPLES, 20000, 20000,\n",
    "            Ksteps=1, normalize=False, m=m_value,\n",
    "        )\n",
    "        _, _, Ktest_data_np = data_collector.get_data()\n",
    "        Ktest_data = torch.from_numpy(Ktest_data_np).float()\n",
    "        state_dim_ds = data_collector.state_dim\n",
    "        u_dim_ds = data_collector.u_dim\n",
    "\n",
    "        # --- no cov ---\n",
    "        covs = []\n",
    "        for _, row in group_no_cov.iterrows():\n",
    "            model, _, _, _ = build_model_from_row(row, device=device)\n",
    "            covs.append(cov_of_latent_z(model, Ktest_data, state_dim_ds, u_dim_ds, device=device))\n",
    "        cov_avg = average_mats(covs)\n",
    "        latent_cov[(m_value, False)] = cov_avg\n",
    "        latent_corr[(m_value, False)] = covariance_to_correlation(cov_avg)\n",
    "        cov_small_stats[(m_value, False)] = count_small_offdiag_cov(cov_avg, COV_THRESHOLD)\n",
    "\n",
    "        # --- with cov ---\n",
    "        covs = []\n",
    "        for _, row in group_with_cov.iterrows():\n",
    "            model, _, _, _ = build_model_from_row(row, device=device)\n",
    "            covs.append(cov_of_latent_z(model, Ktest_data, state_dim_ds, u_dim_ds, device=device))\n",
    "        cov_avg = average_mats(covs)\n",
    "        latent_cov[(m_value, True)] = cov_avg\n",
    "        latent_corr[(m_value, True)] = covariance_to_correlation(cov_avg)\n",
    "        cov_small_stats[(m_value, True)] = count_small_offdiag_cov(cov_avg, COV_THRESHOLD)\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # Print quantitative summary (per m, with/without cov-loss)\n",
    "    # -----------------------------------------------------------------\n",
    "    print(\"\\n=== Quantitative covariance-sparsity metric (OFF-DIAGONAL) ===\")\n",
    "    print(f\"Threshold: |cov_ij| < {COV_THRESHOLD:g}\")\n",
    "    for m_value in TARGET_M_VALUES:\n",
    "        a = cov_small_stats.get((m_value, False), None)\n",
    "        b = cov_small_stats.get((m_value, True), None)\n",
    "        if a is None or b is None:\n",
    "            continue\n",
    "        cnt0, tot0, frac0 = a\n",
    "        cnt1, tot1, frac1 = b\n",
    "        delta = frac1 - frac0\n",
    "        print(\n",
    "            f\"m={m_value:>3} | \"\n",
    "            f\"no cov-loss: {cnt0}/{tot0} ({frac0:.2%}) | \"\n",
    "            f\"with cov-loss: {cnt1}/{tot1} ({frac1:.2%}) | \"\n",
    "            f\"Δ={delta:.2%}\"\n",
    "        )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # Plotting (Correlation heatmaps, diagonal INCLUDED)\n",
    "    # -----------------------------------------------------------------\n",
    "    # Correlation should be in [-1, 1]. Use fixed scale for easy comparison.\n",
    "    vmin, vmax = -1.0, 1.0\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(10, 6), constrained_layout=True)\n",
    "\n",
    "    im = None\n",
    "    for col, m_value in enumerate(TARGET_M_VALUES):\n",
    "        for row, use_cov in enumerate([False, True]):\n",
    "            ax = axes[row, col]\n",
    "            mat = latent_corr.get((m_value, use_cov), None)\n",
    "\n",
    "            if mat is None:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            # NO diagonal masking anymore\n",
    "            im = ax.imshow(mat, vmin=vmin, vmax=vmax, cmap=\"coolwarm\")\n",
    "\n",
    "            # Column Headers (Only on top row)\n",
    "            if row == 0:\n",
    "                ax.set_title(f\"$m = {m_value}$\")\n",
    "\n",
    "            # Row Labels (Only on left column)\n",
    "            if col == 0:\n",
    "                label = \"Without $\\mathcal{L}_{cov}$\" if not use_cov else \"With $\\mathcal{L}_{cov}$\"\n",
    "                ax.set_ylabel(f\"{label}\\nLatent Index\")\n",
    "            else:\n",
    "                ax.set_ylabel(\"\")\n",
    "                ax.set_yticks([])\n",
    "\n",
    "            # X Labels (Only on bottom row)\n",
    "            if row == 1:\n",
    "                ax.set_xlabel(\"Latent Index\")\n",
    "            else:\n",
    "                ax.set_xlabel(\"\")\n",
    "                ax.set_xticks([])\n",
    "\n",
    "            # Quantitative annotation (uses COVARIANCE, off-diagonal)\n",
    "            stats = cov_small_stats.get((m_value, use_cov), None)\n",
    "            if stats is not None:\n",
    "                cnt, tot, frac = stats\n",
    "                ax.text(\n",
    "                    0.98, 0.02,\n",
    "                    f\"$|cov|<{COV_THRESHOLD:g}$\\n{cnt}/{tot} ({frac:.1%})\",\n",
    "                    transform=ax.transAxes,\n",
    "                    ha=\"right\", va=\"bottom\",\n",
    "                    fontsize=10,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.25\", facecolor=\"white\", alpha=0.75, edgecolor=\"none\")\n",
    "                )\n",
    "\n",
    "    # Colorbar\n",
    "    if im is not None:\n",
    "        cbar = fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.8, aspect=30)\n",
    "        cbar.set_label(\"Correlation\", fontsize=14)\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "    out_dir = \"./latent_cov_heatmaps\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    pdf_path = os.path.join(out_dir, \"Polynomial_m_sweep_heatmap.pdf\")\n",
    "\n",
    "    fig.savefig(pdf_path, bbox_inches=\"tight\")\n",
    "    print(\"\\n✅ Saved figure to:\", pdf_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec0a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koopman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
